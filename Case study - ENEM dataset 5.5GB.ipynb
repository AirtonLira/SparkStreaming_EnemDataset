{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/gbonesso/enem-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "from pyspark import SparkContext, SQLContext, SparkConf, StorageLevel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAll([('spark.executor.memory', '8g'), ('spark.executor.cores', '4'), \n",
    "                                   ('spark.cores.max', '4'), ('spark.driver.memory','8g')])\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] O sistema não pode encontrar o arquivo especificado: './Datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9d91698580a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./Datasets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] O sistema não pode encontrar o arquivo especificado: './Datasets'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"./Datasets\")\n",
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"./Datasets/microdados_enem_2016_coma.csv\", 100).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NU_INSCRICAO,NU_ANO,CO_MUNICIPIO_RESIDENCIA,NO_MUNICIPIO_RESIDENCIA,CO_UF_RESIDENCIA,SG_UF_RESIDENCIA,NU_IDADE,TP_SEXO,TP_ESTADO_CIVIL,TP_COR_RACA,TP_NACIONALIDADE,CO_MUNICIPIO_NASCIMENTO,NO_MUNICIPIO_NASCIMENTO,CO_UF_NASCIMENTO,SG_UF_NASCIMENTO,TP_ST_CONCLUSAO,TP_ANO_CONCLUIU,TP_ESCOLA,TP_ENSINO,IN_TREINEIRO,CO_ESCOLA,CO_MUNICIPIO_ESC,NO_MUNICIPIO_ESC,CO_UF_ESC,SG_UF_ESC,TP_DEPENDENCIA_ADM_ESC,TP_LOCALIZACAO_ESC,TP_SIT_FUNC_ESC,IN_BAIXA_VISAO,IN_CEGUEIRA,IN_SURDEZ,IN_DEFICIENCIA_AUDITIVA,IN_SURDO_CEGUEIRA,IN_DEFICIENCIA_FISICA,IN_DEFICIENCIA_MENTAL,IN_DEFICIT_ATENCAO,IN_DISLEXIA,IN_DISCALCULIA,IN_AUTISMO,IN_VISAO_MONOCULAR,IN_OUTRA_DEF,IN_SABATISTA,IN_GESTANTE,IN_LACTANTE,IN_IDOSO,IN_ESTUDA_CLASSE_HOSPITALAR,IN_SEM_RECURSO,IN_BRAILLE,IN_AMPLIADA_24,IN_AMPLIADA_18,IN_LEDOR,IN_ACESSO,IN_TRANSCRICAO,IN_LIBRAS,IN_LEITURA_LABIAL,IN_MESA_CADEIRA_RODAS,IN_MESA_CADEIRA_SEPARADA,IN_APOIO_PERNA,IN_GUIA_INTERPRETE,IN_MACA,IN_COMPUTADOR,IN_CADEIRA_ESPECIAL,IN_CADEIRA_CANHOTO,IN_CADEIRA_ACOLCHOADA,IN_PROVA_DEITADO,IN_MOBILIARIO_OBESO,IN_LAMINA_OVERLAY,IN_PROTETOR_AURICULAR,IN_MEDIDOR_GLICOSE,IN_MAQUINA_BRAILE,IN_SOROBAN,IN_MARCA_PASSO,IN_SONDA,IN_MEDICAMENTOS,IN_SALA_INDIVIDUAL,IN_SALA_ESPECIAL,IN_SALA_ACOMPANHANTE,IN_MOBILIARIO_ESPECIFICO,IN_MATERIAL_ESPECIFICO,IN_NOME_SOCIAL,IN_CERTIFICADO,NO_ENTIDADE_CERTIFICACAO,CO_UF_ENTIDADE_CERTIFICACAO,SG_UF_ENTIDADE_CERTIFICACAO,CO_MUNICIPIO_PROVA,NO_MUNICIPIO_PROVA,CO_UF_PROVA,SG_UF_PROVA,TP_PRESENCA_CN,TP_PRESENCA_CH,TP_PRESENCA_LC,TP_PRESENCA_MT,CO_PROVA_CN,CO_PROVA_CH,CO_PROVA_LC,CO_PROVA_MT,NU_NOTA_CN,NU_NOTA_CH,NU_NOTA_LC,NU_NOTA_MT,TX_RESPOSTAS_CN,TX_RESPOSTAS_CH,TX_RESPOSTAS_LC,TX_RESPOSTAS_MT,TP_LINGUA,TX_GABARITO_CN,TX_GABARITO_CH,TX_GABARITO_LC,TX_GABARITO_MT,TP_STATUS_REDACAO,NU_NOTA_COMP1,NU_NOTA_COMP2,NU_NOTA_COMP3,NU_NOTA_COMP4,NU_NOTA_COMP5,NU_NOTA_REDACAO,Q001,Q002,Q003,Q004,Q005,Q006,Q007,Q008,Q009,Q010,Q011,Q012,Q013,Q014,Q015,Q016,Q017,Q018,Q019,Q020,Q021,Q022,Q023,Q024,Q025,Q026,Q027,Q028,Q029,Q030,Q031,Q032,Q033,Q034,Q035,Q036,Q037,Q038,Q039,Q040,Q041,Q042,Q043,Q044,Q045,Q046,Q047,Q048,Q049,Q050']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map dos dados relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddEnemMap = rdd.map(lambda line: (line.split(\",\")[1],line.split(\",\")[3],\n",
    "                                   line.split(\",\")[7],line.split(\",\")[8],line.split(\",\")[9],line.split(\",\")[10],\n",
    "                         line.split(\",\")[-52],line.split(\",\")[-53],line.split(\",\")[-54],line.split(\",\")[-55]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NU_ANO',\n",
       "  'NO_MUNICIPIO_RESIDENCIA',\n",
       "  'TP_SEXO',\n",
       "  'TP_ESTADO_CIVIL',\n",
       "  'TP_COR_RACA',\n",
       "  'TP_NACIONALIDADE',\n",
       "  'NU_NOTA_COMP5',\n",
       "  'NU_NOTA_COMP4',\n",
       "  'NU_NOTA_COMP3',\n",
       "  'NU_NOTA_COMP2'),\n",
       " ('2016', 'Jo�o Pessoa', 'M', '0', '3', '1', '120', '120', '100', '120'),\n",
       " ('2016', 'Vitorino', 'M', '0', '1', '1', '80', '120', '120', '120'),\n",
       " ('2016', 'Salvador', 'M', '0', '3', '1', '100', '80', '80', '100'),\n",
       " ('2016', 'Bel�m', 'M', '0', '1', '1', '120', '140', '120', '120')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddEnemMap.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validando quantidade de partições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partitions: 170\n"
     ]
    }
   ],
   "source": [
    "numPartitions = rddEnemMap.getNumPartitions()\n",
    "print(\"Total partitions: {}\".format(numPartitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando coalesce para evitar o shuffle dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddEnemMap_coalesce = rddEnemMap.coalesce(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partitions: 55\n"
     ]
    }
   ],
   "source": [
    "numPartitions = rddEnemMap_coalesce.getNumPartitions()\n",
    "print(\"Total partitions: {}\".format(numPartitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rddEnemMap_coalesce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------+---------------+-----------+----------------+-------------+-------------+-------------+-------------+\n",
      "|    _1|                  _2|     _3|             _4|         _5|              _6|           _7|           _8|           _9|          _10|\n",
      "+------+--------------------+-------+---------------+-----------+----------------+-------------+-------------+-------------+-------------+\n",
      "|NU_ANO|NO_MUNICIPIO_RESI...|TP_SEXO|TP_ESTADO_CIVIL|TP_COR_RACA|TP_NACIONALIDADE|NU_NOTA_COMP5|NU_NOTA_COMP4|NU_NOTA_COMP3|NU_NOTA_COMP2|\n",
      "|  2016|         Jo�o Pessoa|      M|              0|          3|               1|          120|          120|          100|          120|\n",
      "|  2016|            Vitorino|      M|              0|          1|               1|           80|          120|          120|          120|\n",
      "|  2016|            Salvador|      M|              0|          3|               1|          100|           80|           80|          100|\n",
      "|  2016|               Bel�m|      M|              0|          1|               1|          120|          140|          120|          120|\n",
      "|  2016|            Bras�lia|      F|              2|          1|               1|             |             |             |             |\n",
      "|  2016|           Fortaleza|      M|              0|          3|               1|          100|          120|          160|          100|\n",
      "|  2016|           Fortaleza|      M|              1|          3|               1|             |             |             |             |\n",
      "|  2016|           Fortaleza|      F|              0|          1|               1|          200|          200|          200|          180|\n",
      "|  2016|               Bauru|      F|              0|          1|               1|             |             |             |             |\n",
      "|  2016|           S�o Paulo|      F|              1|          3|               1|           60|          140|          120|          120|\n",
      "|  2016|      Rio de Janeiro|      M|              0|          3|               1|           80|           80|           80|           80|\n",
      "|  2016|             Mossor�|      F|               |          3|               1|             |             |             |             |\n",
      "|  2016|             Vit�ria|      M|              0|          1|               1|             |             |             |             |\n",
      "|  2016|          Parnamirim|      M|              0|          1|               1|           40|          100|          100|          120|\n",
      "|  2016|      Belo Horizonte|      F|              0|          3|               1|             |             |             |             |\n",
      "|  2016|              Recife|      F|              3|          1|               1|           20|           80|           80|           80|\n",
      "|  2016|          Vila Velha|      F|              0|          3|               1|          160|          160|          140|          140|\n",
      "|  2016|            Bras�lia|      M|              0|          1|               1|             |             |             |             |\n",
      "|  2016|        Campo Grande|      F|              0|          1|               1|          160|          180|          160|          160|\n",
      "+------+--------------------+-------+---------------+-----------+----------------+-------------+-------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando Rdd particionado e com dados relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.write.csv(\"./Datasets/enem_importcoluns_load\", sep=',', header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"./Datasets/enem_importcoluns_load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partitions: 55\n"
     ]
    }
   ],
   "source": [
    "numPartitions = rdd.getNumPartitions()\n",
    "print(\"Total partitions: {}\".format(numPartitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_1,_2,_3,_4,_5,_6,_7,_8,_9,_10',\n",
       " 'NU_ANO,NO_MUNICIPIO_RESIDENCIA,TP_SEXO,TP_ESTADO_CIVIL,TP_COR_RACA,TP_NACIONALIDADE,NU_NOTA_COMP5,NU_NOTA_COMP4,NU_NOTA_COMP3,NU_NOTA_COMP2',\n",
       " '2016,Jo�o Pessoa,M,0,3,1,120,120,100,120',\n",
       " '2016,Vitorino,M,0,1,1,80,120,120,120',\n",
       " '2016,Salvador,M,0,3,1,100,80,80,100']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map para obter somente as colunas de Sexo e numero da nota 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddEnemMapGroup = rdd.map(lambda x: (x.split(\",\")[2],x.split(\",\")[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_3', '_10'),\n",
       " ('TP_SEXO', 'NU_NOTA_COMP2'),\n",
       " ('M', '120'),\n",
       " ('M', '120'),\n",
       " ('M', '100')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddEnemMapGroup.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para validar dados da coluna de nota 2 que não contem registro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notContainFloat(line):\n",
    "    try:\n",
    "        tmp = (line[0],float(line[1]))\n",
    "        return tmp\n",
    "    except:\n",
    "        return (\"\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddEnemMapSex = rddEnemMapGroup.map(lambda line: notContainFloat(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map dos dados para 1 = Masculino, 0 = Feminino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddEnemMapSex = rddEnemMapSex.map(lambda line: (1,line[1]) if line[0] == \"M\" \n",
    "                                          else (0,line[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partitions: 55\n"
     ]
    }
   ],
   "source": [
    "numPartitions = rddEnemMapSex.getNumPartitions()\n",
    "print(\"Total partitions: {}\".format(numPartitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para transformar linhas em hash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitioner(line):\n",
    "    return hash(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionado em 2 distribuições pela chave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddEnemMapSexBy = rddEnemMapSex.partitionBy(2, partitioner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partitions: 2\n"
     ]
    }
   ],
   "source": [
    "numPartitions = rddEnemMapSexBy.getNumPartitions()\n",
    "print(\"Total partitions: {}\".format(numPartitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total somatório da nota 2 pela chave de sexo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 385835196.0), (1, 269400931.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dfagregateBykey = rddEnemMapSexBy.aggregateByKey(0,\n",
    "                                       lambda x, y: x + y,\n",
    "                                       lambda x, y: x + y)\n",
    "dfagregateBykey.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema = StructType([\n",
    "    StructField(\"NU_ANO\",IntegerType(), True),\n",
    "    StructField(\"NO_MUNICIPIO_RESIDENCIA\",StringType(), True),\n",
    "    StructField(\"TP_SEXO\",StringType(), True),\n",
    "    StructField(\"TP_ESTADO_CIVIL\",IntegerType(), True),\n",
    "    StructField(\"TP_COR_RACA\",IntegerType(), True),\n",
    "    StructField(\"TP_NACIONALIDADE\",IntegerType(), True),\n",
    "    StructField(\"NU_NOTA_COMP5\",IntegerType(), True),\n",
    "    StructField(\"NU_NOTA_COMP4\",IntegerType(), True),\n",
    "    StructField(\"NU_NOTA_COMP3\",IntegerType(), True),\n",
    "    StructField(\"NU_NOTA_COMP2\",IntegerType(), True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "df = spark.read.csv(\"./Datasets/enem_importcoluns_load\", header=True, sep=\",\", schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------+-------+---------------+-----------+----------------+-------------+-------------+-------------+-------------+\n",
      "|NU_ANO|NO_MUNICIPIO_RESIDENCIA|TP_SEXO|TP_ESTADO_CIVIL|TP_COR_RACA|TP_NACIONALIDADE|NU_NOTA_COMP5|NU_NOTA_COMP4|NU_NOTA_COMP3|NU_NOTA_COMP2|\n",
      "+------+-----------------------+-------+---------------+-----------+----------------+-------------+-------------+-------------+-------------+\n",
      "|  2016|                Itabuna|      F|              0|          1|               1|            0|          120|          120|          120|\n",
      "|  2016|                    Exu|      F|              0|          3|               1|         null|         null|         null|         null|\n",
      "|  2016|            Sete Lagoas|      M|              0|          3|               1|           20|          120|          100|          120|\n",
      "|  2016|                 Trairi|      M|              0|          3|               1|         null|         null|         null|         null|\n",
      "|  2016|               Salvador|      F|              0|          0|               1|         null|         null|         null|         null|\n",
      "|  2016|               Santar�m|      F|              0|          3|               1|          120|          140|          160|          160|\n",
      "|  2016|                Grossos|      F|              2|          3|               1|         null|         null|         null|         null|\n",
      "|  2016|           Porto Alegre|      F|              0|          2|               1|         null|         null|         null|         null|\n",
      "|  2016|              Barreiras|      F|              0|          3|               1|           80|          160|          120|          120|\n",
      "|  2016|           Juiz de Fora|      F|              0|          3|               1|           40|          100|           80|           80|\n",
      "|  2016|              S�o Paulo|      F|              0|          3|               1|          120|          160|          120|          120|\n",
      "|  2016|              Bela Cruz|      F|              0|          3|               1|          100|          120|          120|          120|\n",
      "|  2016|              Fortaleza|      F|              1|          3|               1|           80|          120|          120|          120|\n",
      "|  2016|                 Mucuri|      F|              1|          3|               1|           40|          100|           80|          100|\n",
      "|  2016|            Nova Igua�u|      F|              1|          1|               1|           80|          100|           80|          100|\n",
      "|  2016|                 Pocon�|      M|              0|          3|               1|           80|           80|           80|           80|\n",
      "|  2016|                Eus�bio|      F|              0|          2|               1|           80|          100|          120|          120|\n",
      "|  2016|        Siqueira Campos|      F|              0|          1|               1|           40|          100|          100|          120|\n",
      "|  2016|                Surubim|      M|              0|          2|               1|           80|          100|           80|          120|\n",
      "|  2016|              Mirandiba|      F|              0|          5|               1|          120|          120|          120|          140|\n",
      "+------+-----------------------+-------+---------------+-----------+----------------+-------------+-------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.select('NU_ANO', 'NO_MUNICIPIO_RESIDENCIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', \n",
    "                'TP_NACIONALIDADE', 'NU_NOTA_COMP5', 'NU_NOTA_COMP4', 'NU_NOTA_COMP3', 'NU_NOTA_COMP2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"NU_NOTA_COMP2\", df2[\"NU_NOTA_COMP2\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.select(\"TP_SEXO\",\"NU_NOTA_COMP2\").groupBy(\"TP_SEXO\").sum(\"NU_NOTA_COMP2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(TP_SEXO='TP_SEXO', sum(NU_NOTA_COMP2)=None)\n",
      "Row(TP_SEXO='F', sum(NU_NOTA_COMP2)=385835196.0)\n",
      "Row(TP_SEXO='M', sum(NU_NOTA_COMP2)=269400931.0)\n",
      "Wall time: 6.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for x in df3.take(4): print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Média da nota 2 por ano e município:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------+------------------+---------+\n",
      "|NU_ANO|NO_MUNICIPIO_RESIDENCIA|             NOTA2|Registros|\n",
      "+------+-----------------------+------------------+---------+\n",
      "|  2016|           Carlos Gomes|131.57894736842104|       28|\n",
      "|  2016|                Niter�i| 130.0946179306375|    19869|\n",
      "|  2016|   S�o Jo�o das Duas...|             130.0|       50|\n",
      "|  2016|            Vila Flores|129.84126984126985|       78|\n",
      "|  2016|      Aparecida d'Oeste|129.04109589041096|      108|\n",
      "|  2016|   Santa Cec�lia do Sul|128.64864864864865|       51|\n",
      "|  2016|   Vista Alegre do P...|128.57142857142858|       34|\n",
      "|  2016|        Dores de Campos| 128.1045751633987|      439|\n",
      "|  2016|        Estrela d'Oeste|             127.5|      169|\n",
      "|  2016|    S�o Domingos do Sul|             127.5|       80|\n",
      "|  2016|          Nova Friburgo|126.85108695652174|     5162|\n",
      "|  2016|                   Ermo|125.94594594594595|       56|\n",
      "|  2016|               Ariranha|          125.8125|      125|\n",
      "|  2016|   Concei��o da Barr...|125.73770491803279|      168|\n",
      "|  2016|               Botucatu|125.61115668580804|     3281|\n",
      "|  2016|         Laje do Muria�|125.57377049180327|      175|\n",
      "|  2016|           Pedran�polis|125.45454545454545|       34|\n",
      "|  2016|                  Uchoa|125.20547945205479|      200|\n",
      "|  2016|             Tiradentes|125.17374517374517|      432|\n",
      "|  2016|       Ariranha do Iva�|             125.0|       18|\n",
      "+------+-----------------------+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Wall time: 8.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spark.sql(\"\"\"SELECT NU_ANO, NO_MUNICIPIO_RESIDENCIA, avg(NU_NOTA_COMP2) AS NOTA2, COUNT(*) AS Registros \n",
    "          FROM tmp\n",
    "          group by nu_ano, no_municipio_residencia\n",
    "          order by avg(nu_nota_comp2) desc\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_notas = spark.sql(\"\"\"SELECT NU_ANO, NO_MUNICIPIO_RESIDENCIA, avg(NU_NOTA_COMP2) AS NOTA2, COUNT(*) AS Registros \n",
    "          FROM tmp\n",
    "          group by nu_ano, no_municipio_residencia\n",
    "          order by avg(nu_nota_comp2) desc\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando dados de populacional por municipio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_populacao_mun = spark.read.csv(\"./Datasets/estimativa_TCU_2016_20170614.csv\", header=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+--------------------+------------------+----+----+\n",
      "| UF|COD. UF|COD. MUNIC|   NOME DO MUNIC�PIO|POPULA��O ESTIMADA| _c5| _c6|\n",
      "+---+-------+----------+--------------------+------------------+----+----+\n",
      "| RO|     11|     00015|Alta Floresta D'O...|            25.506|null|null|\n",
      "| RO|     11|     00023|           Ariquemes|           105.896|null|null|\n",
      "| RO|     11|     00031|              Cabixi|             6.289|null|null|\n",
      "| RO|     11|     00049|              Cacoal|            87.877|null|null|\n",
      "| RO|     11|     00056|          Cerejeiras|            17.959|null|null|\n",
      "+---+-------+----------+--------------------+------------------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_populacao_mun.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldColumns = df_populacao_mun.schema.names[:-2]\n",
    "newColumns = [\"UF\",\"COD_UF\",\"COD_MUNIC\",\"NOME_MUNIC\",\"POPULACAO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in zip(oldColumns,newColumns): df_populacao_mun = df_populacao_mun.withColumnRenamed(x[0],x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+--------------------+---------+----+----+\n",
      "| UF|COD_UF|COD_MUNIC|          NOME_MUNIC|POPULACAO| _c5| _c6|\n",
      "+---+------+---------+--------------------+---------+----+----+\n",
      "| RO|    11|    00015|Alta Floresta D'O...|   25.506|null|null|\n",
      "| RO|    11|    00023|           Ariquemes|  105.896|null|null|\n",
      "| RO|    11|    00031|              Cabixi|    6.289|null|null|\n",
      "| RO|    11|    00049|              Cacoal|   87.877|null|null|\n",
      "| RO|    11|    00056|          Cerejeiras|   17.959|null|null|\n",
      "+---+------+---------+--------------------+---------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_populacao_mun.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_populacao_mun.createOrReplaceTempView(\"ibge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter-dash in c:\\users\\junin\\anaconda3\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: dash in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-dash) (1.19.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-dash) (7.19.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-dash) (1.3.3)\n",
      "Requirement already satisfied: flask in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-dash) (1.1.2)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-dash) (5.3.4)\n",
      "Requirement already satisfied: requests in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-dash) (2.24.0)\n",
      "Requirement already satisfied: ansi2html in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-dash) (1.6.0)\n",
      "Requirement already satisfied: flask-compress in c:\\users\\junin\\anaconda3\\lib\\site-packages (from dash->jupyter-dash) (1.9.0)\n",
      "Requirement already satisfied: dash-table==4.11.2 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from dash->jupyter-dash) (4.11.2)\n",
      "Requirement already satisfied: dash-renderer==1.9.0 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from dash->jupyter-dash) (1.9.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\junin\\anaconda3\\lib\\site-packages (from dash->jupyter-dash) (4.14.3)\n",
      "Requirement already satisfied: dash-core-components==1.15.0 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from dash->jupyter-dash) (1.15.0)\n",
      "Requirement already satisfied: future in c:\\users\\junin\\anaconda3\\lib\\site-packages (from dash->jupyter-dash) (0.18.2)\n",
      "Requirement already satisfied: dash-html-components==1.1.2 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from dash->jupyter-dash) (1.1.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (50.3.1.post20201107)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.17.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (3.0.8)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.4.4)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.7.5)\n",
      "Requirement already satisfied: pygments in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (2.7.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (5.0.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.2.0)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from retrying->jupyter-dash) (1.15.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from flask->jupyter-dash) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from flask->jupyter-dash) (7.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from flask->jupyter-dash) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from flask->jupyter-dash) (2.11.2)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (6.0.4)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\junin\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (6.1.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from requests->jupyter-dash) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from requests->jupyter-dash) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from requests->jupyter-dash) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from requests->jupyter-dash) (2.10)\n",
      "Requirement already satisfied: brotli in c:\\users\\junin\\anaconda3\\lib\\site-packages (from flask-compress->dash->jupyter-dash) (1.0.9)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython->jupyter-dash) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\junin\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\junin\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->jupyter-dash) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->flask->jupyter-dash) (1.1.1)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter-dash) (19.0.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter-dash) (4.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\junin\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter-dash) (227)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\junin\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from pandas) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\junin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jupyter-dash\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analise de média das notas 2 por municipio relacionando com dataset de quantidade populacional por municipio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnalise = spark.sql(\"\"\"SELECT A.NU_ANO, A.NO_MUNICIPIO_RESIDENCIA, avg(A.NU_NOTA_COMP2) AS MEDIA_NOTA2, COUNT(*) AS Registros,\n",
    "          B.POPULACAO, (COUNT(*) / B.POPULACAO) PERCENT_POPUL_REGI\n",
    "          FROM tmp AS A\n",
    "          LEFT JOIN ibge AS B ON (B.NOME_MUNIC = A.NO_MUNICIPIO_RESIDENCIA)\n",
    "          group by A.nu_ano, A.no_municipio_residencia, B.POPULACAO\n",
    "          order by avg(A.nu_nota_comp2) desc\n",
    "          \"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_ANO</th>\n",
       "      <th>NO_MUNICIPIO_RESIDENCIA</th>\n",
       "      <th>MEDIA_NOTA2</th>\n",
       "      <th>Registros</th>\n",
       "      <th>POPULACAO</th>\n",
       "      <th>PERCENT_POPUL_REGI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>Carlos Gomes</td>\n",
       "      <td>131.578947</td>\n",
       "      <td>28</td>\n",
       "      <td>1.560</td>\n",
       "      <td>17.948718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>Niter�i</td>\n",
       "      <td>130.094618</td>\n",
       "      <td>19869</td>\n",
       "      <td>497.883</td>\n",
       "      <td>39.906966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>S�o Jo�o das Duas Pontes</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>50</td>\n",
       "      <td>2.607</td>\n",
       "      <td>19.179133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>Vila Flores</td>\n",
       "      <td>129.841270</td>\n",
       "      <td>78</td>\n",
       "      <td>3.373</td>\n",
       "      <td>23.124815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>Aparecida d'Oeste</td>\n",
       "      <td>129.041096</td>\n",
       "      <td>108</td>\n",
       "      <td>4.362</td>\n",
       "      <td>24.759285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NU_ANO   NO_MUNICIPIO_RESIDENCIA  MEDIA_NOTA2  Registros POPULACAO  \\\n",
       "0  2016.0              Carlos Gomes   131.578947         28     1.560   \n",
       "1  2016.0                   Niter�i   130.094618      19869   497.883   \n",
       "2  2016.0  S�o Jo�o das Duas Pontes   130.000000         50     2.607   \n",
       "3  2016.0               Vila Flores   129.841270         78     3.373   \n",
       "4  2016.0         Aparecida d'Oeste   129.041096        108     4.362   \n",
       "\n",
       "   PERCENT_POPUL_REGI  \n",
       "0           17.948718  \n",
       "1           39.906966  \n",
       "2           19.179133  \n",
       "3           23.124815  \n",
       "4           24.759285  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAnalise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json \n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NotasSchema = StructType().add(\"NO_MUNICIPIO_RESIDENCIA\",\"string\").add(\"NOTA2\",\"double\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializando streamFile para leitura de novas notas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "novasNotasDf = spark.readStream.option(\"sep\", \";\").option(\"header\", \"true\").schema(NotasSchema).csv(\"./Datasets/new_notas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "novasNotasDf.createOrReplaceTempView(\"novasnotas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalMunicipio = spark.sql(\"SELECT NO_MUNICIPIO_RESIDENCIA, SUM(NOTA2) AS TOTAL_NOTA_2 FROM novasnotas GROUP BY NO_MUNICIPIO_RESIDENCIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalMunicipio = totalMunicipio.coalesce(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ou = novasNotasDf.groupBy(\"NU_MUNICIPIO_RESIDENCIA\").sum(\"TOTAL_NOTA_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = totalMunicipio.writeStream.outputMode(\"complete\").format(\"console\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
